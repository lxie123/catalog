tags:
  - AI/Machine Learning
  - Serverless
title: Kubeflow KServe
summary: "Serverless platform for deploying, monitoring, and managing ML models on Kubernetes."
logo: ./assets/kserve_logo_icon.svg # https://github.com/kserve/artwork/blob/main/icon/color/k-serve-icon-color.svg
logo_big: ./assets/kserve_logo.svg # https://github.com/kserve/artwork/blob/main/color/k-serve-color.svg
description: |
    k0rdent facilitates the deployment and lifecycle management of [KServe](https://kserve.github.io/website/latest/){ target="_blank" }
    within Kubernetes clusters by leveraging its multi-cluster orchestration capabilities.
    KServe provides a Kubernetes-native platform for serving and managing machine learning models with high performance and scalability.
    
    KServe builds on Kubernetes to provide a standardized, scalable, and reliable solution for deploying, monitoring, and managing 
    machine learning models in production. With features like traffic management, canary deployments, and autoscaling, KServe enables 
    seamless deployment of models across various frameworks including [TensorFlow](https://www.tensorflow.org/){ target="_blank" },
    [PyTorch](https://pytorch.org/){ target="_blank" }, [scikit-learn](https://scikit-learn.org/){ target="_blank" },
    [XGBoost](https://xgboost.readthedocs.io/){ target="_blank" }, and [ONNX](https://onnx.ai/){ target="_blank" }.
    
    KServe consists of two main components:

    1. **KServe CRDs** - Custom Resource Definitions that provide the foundation for KServe's functionality
    2. **KServe Controller** - The controller that implements serverless model serving capabilities
    
    Through k0rdent, users can easily install and manage KServe across multiple clusters, providing a centralized control plane
    to monitor health, enforce policies, and enable enterprise-grade machine learning serving. This application provides the ability to deploy
    the KServe Controller in Serverless mode without ModelMesh functionality enabled, which is optimized for environments 
    where autoscaling and scale-to-zero capabilities are prioritized.
    
    By deploying KServe from the catalog, k0rdent enables users to build and scale ML inference services while leveraging Kubernetes-native infrastructure.
# support_link:
install_code: |
    ~~~bash
    helm install kserve-crd oci://ghcr.io/k0rdent/catalog/charts/kserve-crd-service-template \
      --version v0.15.0 -n kcm-system
    helm install kserve oci://ghcr.io/k0rdent/catalog/charts/kserve-service-template \
      --version v0.15.0 -n kcm-system
    ~~~
verify_code: |
    ~~~bash
    kubectl get servicetemplates -A
    # NAMESPACE    NAME               VALID
    # kcm-system   kserve-crd-v0-15-0 true
    # kcm-system   kserve-v0-15-0     true
    ~~~
deploy_code: |
    ~~~yaml
    apiVersion: k0rdent.mirantis.com/v1alpha1
    kind: MultiClusterService
    metadata:
      name: kserve
    spec:
      clusterSelector:
        matchLabels:
          group: demo
      serviceSpec:
        services:
        - template: istio-base-1-24-3
          name: istio-base
          namespace: istio-system
        - template: istiod-1-24-3
          name: istiod
          namespace: istio-system
        - template: istio-gateway-1-24-3
          name: istio-gateway
          namespace: istio-system
        - template: cert-manager-1-17-2
          name: cert-manager
          namespace: istio-system
          values: |
            cert-manager:
              crds:
                enabled: true
        - template: knative-operator-1-17-4
          name: knative-operator
          namespace: istio-system
        # First deploy KServe CRDs
        - template: kserve-crd-v0-15-0
          name: kserve-crd
          namespace: istio-system
        # Then deploy KServe Controller
        - template: kserve-v0-15-0
          name: kserve
          namespace: istio-system
          values: |
            kserve:
              controller:
                deploymentMode: Serverless
              modelmesh:
                enabled: false
    ~~~
doc_link: https://kserve.github.io/website/master/get_started/

# test settings
test_deploy_chart: false
test_wait_for_pods: "kserve-controller-manager-"
